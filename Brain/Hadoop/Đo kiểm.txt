cd /usr/hdp/current/spark2-client/bin

./spark-sql --deploy-mode client --master yarn --name thai --conf "spark.dynamicAllocation.enabled=false" --conf "spark.sql.shuffle.partitions=10" --num-executors 3 --executor-cores 4 --executor-memory 4G

-e "use database; insert into table Fact_HTTP_MDO_TRANS_LOG_END_HOUR select * from 10_Staging2HR_HTTP_MDO_TRANS_LOG_END_HOUR;"


big
staging http: load data -> 16.064s
http: insert into fact 48.973s
http: insert into dy 25.342s 

big 
staging https: load data -> 70.949
https: insert into fact 39.116s

cd /home/hdp/kylin/bin
./kylin.sh start


spark
dim_cell_info_cells -> 21.707s

dim_cell_info_cells_current -> 27.483s

20_HR_Fact_HTTP_MDO_TRANS_LOG_END_HOUR -> 390.114s, 323.283s, 324.218s       324.857s
20_HR_Fact_HTTP_MDO_TRANS_LOG_END_HOUR_HIVE -> 283.13s, 321.139s


SQL-APIConsumer
https://github.com/geral2/SQL-APIConsumer