Integrating Apache Hive with Spark and BI: https://docs.cloudera.com/HDPDocuments/HDP3/HDP-3.0.0/integrating-hive/content/hive_connect_hive_to_apache_superset.html
1 số lỗi trong hive: https://www.ibm.com/support/knowledgecenter/STXKQY_BDA_SHR/bl1adv_hadooptierfaq.htm


desc table1;
desc formatted tab1;


create table table1 (col1 string, col2 array<string>, col3 string, col4 int) row format delimited fields terminated by ',' collection items terminated by ':' lines terminated by '\n' stored as textfile;
create table table2 (col1 string, col2 array<string>, col3 string, col4 int);
create table table2 (col1 string, col2 array<string>, col3 string, col4 int) stored as textfile tblproperties("skip.header.line.count"="3");


create table table3 (col1 string,col2 array<string>,col3 string,col4 int) row format delimited fields terminated by ',' collection items terminated by ':' lines terminated by '\n' stored as textfile location '/user/thaidh/table3';

    /home/hive/table1.txt nằm trong hive@192.168.0.172
load data local inpath '/home/hive/table1.txt' into table table1;

pscp G:\NghiemTuc\Study\Downloads\Hadoop\hive\table1.txt hive@192.168.0.172:/home/hive

create external table: the data will be controlled by HDFS and not Hive. in external table, if we are dropping that table, only metadata will be lost, but the actual data in the HDFS location will still be present. And moreover, in external table data, it allows other applications also to access this data. Whichever application is aligned by HDFS security, it can access this data. But in our internal table, we have to access the data through Hive only.

insert into table tab select col1, col2, col3 from emp_tab;

insert overwrite table tab select col1, col2, col3 from emp_tab where col3 = 'Developer';

create table developer_tab(id int, name string, desg string) stored as textfile;
create table manager_tab(id int, name string, desg string) stored as textfile;
from emp_tab insert into table developer_tab select col1, col2, col3 where col3 = 'Developer' insert into table manager_tab select col1, col2, col3 where col3 = 'Mgr';


alter table tab add columns (col4 string, col5 int);
alter table tab change col1 col1 int after col2; -> đang lỗi
alter table tab change column col2 new_col2 string;
alter table tab rename to tab1;
alter table tab1 replace columns (id int, name string);
alter table tab1 set tblproperties('auto.purge'='true');
alter table tab1 set fileformat avro; -> đang lỗi
alter table table1 enable no_drop; -> The CASCADE clause for NO_DROP was added in HIVE 0.8.0 (HIVE-2605). This functionality was removed in Hive 2.0.0. Hive này là hive 3.1.0. offline cũng thế


order by col2: sắp xếp toàn bộ
sort by col2: chia đôi các bản ghi ra các reducer và thực hiện sắp xếp
distribute by: phân chia các bản ghi trùng nhau ra các reducer
cluster by col2: distribute by + sort by

select * from tbl5 sort by col2 desc;
select * from tbl5 cluster by col2;


select lpad(col3, 10, 'v') from table1;
select repeat(col3, 2) from table1;
select reverse(col3) from table1;
select if(col3="England", col1, col4) from table1;

explode() lấy một mảng làm đầu vào và xuất các phần tử của mảng thành các hàng riêng biệt
select author_name, dummy_booksname from table2 lateral view explode(books_name) dummy as dummy_booksname;
select key, value from table3 lateral view explode(col1) dummy as key, value; -> tách key, value, chưa thử

select 'hadoop' rlike 'has'; -> true

