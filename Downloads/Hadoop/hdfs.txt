https://www.javatpoint.com/hadoop-tutorial
https://data-flair.training/blogs/hadoop-hdfs-tutorial/

sh docker-deploy-hdp30.sh

docker stop sandbox-hdp
docker stop sandbox-proxy

docker start sandbox-hdp
docker start sandbox-proxy


hahoop fs -ls
hahoop fs -ls abc
hadoop fs -mkdir abc
hadoop fs -copyFromLocal u.data abc/u.data
hadoop fs -rm abc/u.data
hadoop fs -rmdir abc
hadoop fs -chmod -R 777 wordcount : phân quyền
hdfs getconf -namenodes
hdfs fsck / -files -blocks -locations : kiểm tra block datanode

wget http://media.sundog-soft.com/hadoop/Spark.zip
wget http://media.sundog-soft.com/hadoop/ml-100k/u.data
wget http://media.sundog-soft.com/hadoop/ml-100k/u.item
wget http://media.sundog-soft.com/hadoop/RatingsBreakdown.py
wget media.sundog-soft.com/hadoop/example.conf
wget media.sundog-soft.com/hadoop/flumelogs.conf

pscp root@192.168.0.157:/root/.ssh/id_rsa .










sqoop import --connect jdbc:mysql://localhost/movielens --driver com.mysql.jdbc.Driver --username root --password hadoop --table movies -m 1 --hive-import

GRANT ALL PRIVILEGES ON movielens.* to ''@'localhost';


sqoop import --connect jdbc:mysql://localhost/movielens --username root --password hadoop --mysql-delimiters --table alo -m 1 --hive-import



CREATE TABLE alo (
  id integer NOT NULL,
  c1 varchar(255),
  c2 varchar(255),
  c3 varchar(255),
  PRIMARY KEY (id)
);

LOAD DATA INFILE '/var/lib/mysql-files/alo.csv' 
INTO TABLE alo
FIELDS TERMINATED BY ',' 
LINES TERMINATED BY '\n'
IGNORE 0 ROWS;

573 | Body Snatchers (1993) | 1993-01-01   |
| 670 | Body Snatchers (1993) | 1993-01-01 

docker run -d -m 8G -p 7070:7070 -p 8088:8088 -p 50070:50070 -p 8032:8032 -p 8042:8042 -p 16010:16010 2cd68ccd1e5d


https://github.com/YotpoLtd/metorikku




Definition of FQDN (Fully Qualified Domain Name)


ls /etc/hadoop/conf/ : file config hdfs
ls /etc/hive/conf/ : file config hive












